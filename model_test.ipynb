{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2594142b1d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    \"\"\"Implement embedding layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, vector_size, vocab_size, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            vector_size {int} -- word embedding size.\n",
    "            vocab_size {int} -- vocabulary size.\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            dropout {float} -- dropout rate. (default: {0.5})\n",
    "        \"\"\"\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        self.vector_size = vector_size\n",
    "        self.embed = nn.Embedding(vocab_size, vector_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def load(self, vectors):\n",
    "        \"\"\"Load pre-trained embedding weights.\n",
    "        \n",
    "        Arguments:\n",
    "            vectors {torch.Tensor} -- from \"TEXT.vocab.vectors\".\n",
    "        \"\"\"\n",
    "        self.embed.weight.data.copy_(vectors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x {torch.Tensor} -- input tensor with shape [batch_size, seq_length]\n",
    "        \"\"\"\n",
    "        e = self.embed(x)\n",
    "        return self.dropout(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embed): Embedding(100, 10)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = EmbeddingLayer(vector_size=10, vocab_size=100)\n",
    "embedding_layer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 99, (32, 20), dtype=torch.long).to(device)  # [batch_size, seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 10])\n"
     ]
    }
   ],
   "source": [
    "embeded = embedding_layer(x)\n",
    "print(embeded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingLayer(nn.Module):\n",
    "    \"\"\"BiLSTM encoder which encodes both the premise and hypothesis.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncodingLayer, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
    "                            num_layers=1,\n",
    "                            bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x {torch.Tensor} -- input embeddings with shape [batch, seq_len, input_size]\n",
    "\n",
    "        Returns:\n",
    "            output {torch.Tensor} -- [batch, seq_len, num_directions * hidden_size]\n",
    "        \"\"\"\n",
    "        self.lstm.flatten_parameters()\n",
    "        output, _ = self.lstm(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "encoding_layer = EncodingLayer(input_size=10, hidden_size=15).to(device)\n",
    "outputs = encoding_layer(embeded)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Inference Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalInferenceModel(nn.Module):\n",
    "    \"\"\"The local inference model introduced in the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LocalInferenceModel, self).__init__()\n",
    "        self.softmax_1 = nn.Softmax(dim=1)\n",
    "        self.softmax_2 = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, p, h, p_mask, h_mask):\n",
    "        \"\"\"Apply local inference to premise and hyopthesis.\n",
    "\n",
    "        Arguments:\n",
    "            p {torch.Tensor} -- p has shape [batch, seq_len_p, 2 * hidden_size]\n",
    "            h {torch.Tensor} -- h has shape [batch, seq_len_h, 2 * hidden_size]\n",
    "            p_mask {torch.Tensor (int)} -- p has shape [batch, seq_len_p], 0 in the mask\n",
    "                means padding.\n",
    "            h_mask {torch.Tensor (int)} -- h has shape [batch, seq_len_h]\n",
    "\n",
    "        Returns:\n",
    "            m_p, m_h {torch.Tensor} -- tensor with shape [batch, seq_len, 8 * hidden_size]\n",
    "        \"\"\"\n",
    "        # equation 11 in the paper:\n",
    "        e = torch.matmul(p, h.transpose(1, 2))  # [batch, seq_len_p, seq_len_h]\n",
    "        # masking the scores for padding tokens\n",
    "        inference_mask = torch.matmul(p_mask.unsqueeze(2).float(),\n",
    "                                      h_mask.unsqueeze(1).float())\n",
    "        e.masked_fill_(inference_mask < 1e-7, -1e7)\n",
    "        \n",
    "        # equation 12 & 13 in the paper:\n",
    "        h_score, p_score = self.softmax_1(e), self.softmax_2(e)\n",
    "        h_ = h_score.transpose(1, 2).bmm(p)\n",
    "        p_ = p_score.bmm(h)\n",
    "\n",
    "        # equation 14 & 15 in the paper:\n",
    "        m_p = torch.cat((p, p_, p * p_, p - p_), dim=-1)\n",
    "        m_h = torch.cat((h, h_, h * h_, h - h_), dim=-1)\n",
    "\n",
    "        assert inference_mask.shape == e.shape\n",
    "        assert p.shape == p_.shape and h.shape == h_.shape\n",
    "        assert m_p.shape[-1] == p.shape[-1] * 4\n",
    "\n",
    "        return m_p, m_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = LocalInferenceModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4962, 0.5468],\n",
      "         [0.8283, 0.0468],\n",
      "         [0.2201, 0.2501],\n",
      "         [0.8731, 0.6575]],\n",
      "\n",
      "        [[0.5739, 0.3068],\n",
      "         [0.1198, 0.8427],\n",
      "         [0.8958, 0.1384],\n",
      "         [0.0653, 0.8580]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "p, h = torch.rand(2, 4, 2), torch.rand(2, 3, 2)  # [batch, seq_len_p, 2 * hidden_size]\n",
    "p, h = p.to(device), h.to(device)\n",
    "print(p)\n",
    "p_mask = torch.tensor([[1, 1, 1, 1],\n",
    "                       [1, 1, 1, 0]]).to(device)\n",
    "h_mask = torch.tensor([[1, 1, 1],\n",
    "                       [1, 0, 0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_p, m_h = lim(p, h, p_mask, h_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 8])\n",
      "torch.Size([2, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "print(m_p.shape)\n",
    "print(m_h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composition Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionLayer(nn.Module):\n",
    "    \"\"\"The composition layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_size, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            input_size {int} -- input size to the feedforward neural network.\n",
    "            output_size {int} -- output size of the feedforward neural network.\n",
    "            hidden_size {int} -- output hidden size of the LSTM model.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            dropout {float} -- dropout rate (default: {0.5})\n",
    "        \"\"\"\n",
    "        super(CompositionLayer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.F = nn.Linear(input_size, output_size)\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, m):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            m {torch.Tensor} -- [batch, seq_len, input_size]\n",
    "\n",
    "        Returns:\n",
    "            outputs {torch.Tensor} -- [batch, seq_len, hidden_size * 2]\n",
    "        \"\"\"\n",
    "        y = self.dropout(self.F(m))\n",
    "        self.lstm.flatten_parameters()\n",
    "        outputs, _ = self.lstm(y)\n",
    "\n",
    "        assert m.shape[:2] == outputs.shape[:2] and \\\n",
    "            outputs.shape[-1] == self.hidden_size * 2\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = CompositionLayer(input_size=8, output_size=2, hidden_size=2, dropout=0.0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = cl(m_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n",
      "tensor([[[ 0.0476, -0.1567, -0.1715, -0.0444],\n",
      "         [ 0.0467, -0.1456, -0.1759, -0.0279],\n",
      "         [ 0.0470, -0.1518, -0.1633, -0.0458],\n",
      "         [ 0.0465, -0.1692, -0.1712, -0.0173]],\n",
      "\n",
      "        [[ 0.0788, -0.2379, -0.0931, -0.0467],\n",
      "         [ 0.0804, -0.2621, -0.1193, -0.0084],\n",
      "         [ 0.0767, -0.2373, -0.0916, -0.0407],\n",
      "         [ 0.0823, -0.2523, -0.0987, -0.0383]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling(nn.Module):\n",
    "    \"\"\"Apply maxing pooling and average pooling to the outputs of LSTM.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Pooling, self).__init__()\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x {torch.Tensor} -- [batch, seq_len, hidden_size * 2]\n",
    "            x_mask {torch.Tensor} -- [batch, seq_len], 0 in the mask means padding\n",
    "\n",
    "        Returns:\n",
    "            v {torch.Tensor} -- [batch, hidden_size * 4]\n",
    "        \"\"\"\n",
    "        mask_expand = x_mask.unsqueeze(-1).expand(x.shape)\n",
    "        print(x)\n",
    "\n",
    "        # average pooling\n",
    "        x_ = x * mask_expand.float()\n",
    "        print(x_)\n",
    "        v_avg = x_.sum(-2) / x_mask.sum(-1).unsqueeze(-1).float()\n",
    "        \n",
    "        # max pooling\n",
    "        x_ = x.masked_fill(mask_expand == 0, -1e7)\n",
    "        print(x_)\n",
    "        v_max = x_.max(-2).values\n",
    "        \n",
    "        print(v_avg)\n",
    "        print(v_max)\n",
    "\n",
    "        assert v_avg.shape == v_max.shape == (x.shape[0], x.shape[-1])\n",
    "        \n",
    "        return torch.cat((v_avg, v_max), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = Pooling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0476, -0.1567, -0.1715, -0.0444],\n",
      "         [ 0.0467, -0.1456, -0.1759, -0.0279],\n",
      "         [ 0.0470, -0.1518, -0.1633, -0.0458],\n",
      "         [ 0.0465, -0.1692, -0.1712, -0.0173]],\n",
      "\n",
      "        [[ 0.0788, -0.2379, -0.0931, -0.0467],\n",
      "         [ 0.0804, -0.2621, -0.1193, -0.0084],\n",
      "         [ 0.0767, -0.2373, -0.0916, -0.0407],\n",
      "         [ 0.0823, -0.2523, -0.0987, -0.0383]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[ 0.0476, -0.1567, -0.1715, -0.0444],\n",
      "         [ 0.0467, -0.1456, -0.1759, -0.0279],\n",
      "         [ 0.0470, -0.1518, -0.1633, -0.0458],\n",
      "         [ 0.0465, -0.1692, -0.1712, -0.0173]],\n",
      "\n",
      "        [[ 0.0788, -0.2379, -0.0931, -0.0467],\n",
      "         [ 0.0804, -0.2621, -0.1193, -0.0084],\n",
      "         [ 0.0767, -0.2373, -0.0916, -0.0407],\n",
      "         [ 0.0000, -0.0000, -0.0000, -0.0000]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[ 4.7648e-02, -1.5668e-01, -1.7153e-01, -4.4379e-02],\n",
      "         [ 4.6694e-02, -1.4557e-01, -1.7586e-01, -2.7896e-02],\n",
      "         [ 4.7035e-02, -1.5177e-01, -1.6332e-01, -4.5800e-02],\n",
      "         [ 4.6503e-02, -1.6923e-01, -1.7120e-01, -1.7326e-02]],\n",
      "\n",
      "        [[ 7.8772e-02, -2.3789e-01, -9.3106e-02, -4.6675e-02],\n",
      "         [ 8.0353e-02, -2.6209e-01, -1.1928e-01, -8.4424e-03],\n",
      "         [ 7.6699e-02, -2.3734e-01, -9.1596e-02, -4.0657e-02],\n",
      "         [-1.0000e+07, -1.0000e+07, -1.0000e+07, -1.0000e+07]]],\n",
      "       device='cuda:0', grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[ 0.0470, -0.1558, -0.1705, -0.0339],\n",
      "        [ 0.0786, -0.2458, -0.1013, -0.0319]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[ 0.0476, -0.1456, -0.1633, -0.0173],\n",
      "        [ 0.0804, -0.2373, -0.0916, -0.0084]], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "v = pooling(outputs, p_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2493"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.2523 - 0.2565 - 0.2391) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceComposition(nn.Module):\n",
    "    \"\"\"Inference composition described in paper section 3.3\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_size, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            input_size {int} -- input size to the feedforward neural network.\n",
    "            output_size {int} -- output size of the feedforward neural network.\n",
    "            hidden_size {int} -- output hidden size of the LSTM model.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            dropout {float} -- dropout rate (default: {0.5})\n",
    "        \"\"\"\n",
    "        super(InferenceComposition, self).__init__()\n",
    "        self.composition_p = CompositionLayer(input_size,\n",
    "                                              output_size,\n",
    "                                              hidden_size,\n",
    "                                              dropout=dropout)\n",
    "        self.composition_h = deepcopy(self.composition_p)\n",
    "        self.pooling = Pooling()\n",
    "\n",
    "    def forward(self, m_p, m_h, p_mask, h_mask):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            m_p {torch.Tensor} -- [batch, seq_len, input_size]\n",
    "            m_h {torch.Tensor} -- [batch, seq_len, input_size]\n",
    "            mask {torch.Tensor} -- [batch, seq_len], 0 means padding\n",
    "\n",
    "        Returns:\n",
    "            v {torch.Tensor} -- [batch, input_size * 8]\n",
    "        \"\"\"\n",
    "        # equation 16 & 17 in the paper\n",
    "        v_p, v_h = self.composition_p(m_p), self.composition_h(m_h)\n",
    "        # equation 18 & 19 in the paper\n",
    "        v_p_, v_h_ = self.pooling(v_p, p_mask), self.pooling(v_h, h_mask)\n",
    "        # equation 20 in the paper\n",
    "        v = torch.cat((v_p_, v_h_), dim=-1)\n",
    "\n",
    "        assert v.shape == (m_p.shape[0], v_p.shape[-1] * 4)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSoftmax(nn.Module):\n",
    "    \"\"\"Implement the final linear layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, class_num, activation='relu', dropout=0.5):\n",
    "        super(LinearSoftmax, self).__init__()\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            raise ValueError(\"Unknown activation function!!!\")\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            self.dropout,\n",
    "            nn.Linear(input_size, output_size),\n",
    "            self.activation,\n",
    "            self.dropout,\n",
    "            nn.Linear(output_size, class_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x {torch.Tensor} -- [batch, features]\n",
    "\n",
    "        Returns:\n",
    "            logits {torch.Tensor} -- raw, unnormalized scores for each class. [batch, class_num]\n",
    "        \"\"\"\n",
    "        logits = self.mlp(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ESIM import ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "esim = ESIM(3, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.tensor([[2, 3, 4, 1], \n",
    "                  [3, 4, 1, 1]], dtype=torch.long)\n",
    "\n",
    "h = torch.tensor([[2, 3, 1, 1], \n",
    "                  [3, 1, 1, 1]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = esim(p, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
